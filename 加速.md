# 加速
1. 使用C语言等替代关键函数。如指标库TA-Lib就是用C语言实现的
2. 减少跨语言调用次数。循环调用talib.SMA，还不如调用一次bottleneck.move_mean
3. 易用性上，numba优于Cython。因为Cython对不同Python版本不同操作系统要分别编译，过于复杂

## 长表与宽表
1. 长表
    1. 如同数据库，每一列为一个字段，如开高低收。必定有两个关键的列做为索引，一列表示股票代码，另一表示时间
    2. 两个索引中有大量重复值，如果只存一个字段利用率只有1/3，得存多个字段才经济
    3. 两个关键字段最好如同数据库一样建B+树索引，否则这两个字段可能因数据太多无法加载到内存
    4. 两个索引的排序先后也对速度有影响。
        1. 先时间分组。真实场景。数据也是按时间生成的。适合做横截面，比如同一天所有股票的涨跌幅排序
        2. 先股票分组，组内时间排序。适合历史分析。可以快速将一指股票取出，NaN也提前就drop了，计算技术指标也方便
2. 宽表
    1. 整表为一个字段，例如都为收盘价，列头为股票代码，索引为时间
    2. 由于上市时间有先后，二维矩阵会出现大量NaN，停牌也会出现NaN，空间利用率低
    3. 停牌中段出现的空值对talib这类的指标计算有影响，必须特别处理才行
    4. 整块存储时，一支股票为一列，这一列均匀分布在文件中，为了加载这列股票，整个文件都必须加载，超大文件时根本不可行
    5. 列式存储时,按整表取出，底层4000多支股票合并会占用大量空间和时间

## 技术指标计算难点
1. 股票支数太多4000多支，talib至少要调用4000多次，单核很难在3s内下次行情推送过来前计算完成
2. 由于GIL的原因，IO密集型可以用多线程，而计算密集型只能用多进程
    1. 多进程最大的问题是数据跨进程。数据序列化和反序列化才能传给子进程，而数据通常几个G，序列化不现实
    2. 共存内存和内存文件映射是一个不错的方案
        1. 宽表。大文件会被全量加载，内存吃紧
        2. 长表。索引需要一个好的机制
3. 无论哪种方案都对大数据量都比较麻烦

## 方案
1. 由于NaN处理实在麻烦
2. 二维计算对各种指标库要求太高。

所以还是用长表，然后配合groupby比较方便，
1. 算指标时按股票代码分组，按时间排序。为了加速，最好每天收盘后就做好排序整理
2. 算横截面时按时间分组

指标计算简单了，但只利用到了单核，计算还是慢。文件还大。多进程时又受限于数据序列化

## 分治
1. 通过某种方法将数据分到不同文件，但又不能分成4000多个文件，打开文件就是比较占资源的事。
2. 通过股票代码后一位，可以均匀分布10个文件，10个进程分别处理。
3. 根据数据量的大小，可以最后两位分成100个，或100%5分成20个，需要进行取舍
4. 分到了10个文件，如果要做横截面，还是得将10个文件先加载合并。所以在时间上也得分割，否则也加载不上。日线可以按年分割，分钟可以按月割等。